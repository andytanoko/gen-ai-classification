{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7A5on_E9xQSC"
   },
   "source": [
    "\n",
    "<h1><center><font size=10> Generative AI for NLP Program</center></font></h1>\n",
    "<h1><center> Project </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkypp72Oa4LD",
    "tags": []
   },
   "source": [
    "# **GA-NLP Project: Financial Product Complaint Classification and Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exBRHi0DbHFT",
    "tags": []
   },
   "source": [
    "## **Business Context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJfHP45hZpwW",
    "tags": []
   },
   "source": [
    "### **Description**\n",
    "*In the modern financial industry, customer complaints play a crucial role in identifying areas where financial institutions can improve their services. Effectively categorizing these complaints into specific product categories, such as credit reports, student loans, or money transfers, is essential for addressing customer concerns promptly by routing the tickets to relevant personnel. Leveraging Generative AI for text classification can help financial institutions better understand customer grievances and respond more efficiently. Apart from this, a summary of the customer complaint helps the support personnel quickly grasp the gist of the grievance*\n",
    "\n",
    "### **Objective**\n",
    "*The primary goal of this project is to utilize Generative AI techniques to improve the classification and summarization of customer complaints in the financial sector.\n",
    "Specifically, the project will focus on:*\n",
    "\n",
    "1. **Text-to-Label Classification:** *Implementing Zero-shot and Few-shot prompting methods to accurately classify customer complaints into relevant product categories.*\n",
    "2. **Text-to-Text Summarization:** *Using Zero-shot prompting to generate concise summaries of customer complaints, enabling more personalized and effective responses.*\n",
    "\n",
    "### **Conclusion**\n",
    "*Upon completing this project, you will have the capability to develop solutions for LLM-based text classification and summarization. These tools will enable financial institutions to automate the complaint handling process, leading to faster, more accurate responses to customer issues, improved customer satisfaction, and enhanced compliance with industry regulations. This project will also provide you with valuable skills and experience that can be applied to a range of real-world business challenges.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "na6DoDeQBIbn",
    "tags": []
   },
   "source": [
    "# **Section 1 : Setting Up for Prompt Engineering with Mistral Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcGMygn3_Mq9",
    "tags": []
   },
   "source": [
    "### **Install & Importing neccessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "REVTReY_day6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Requirement already satisfied: ipywidgets in /home/andy/jupyter_venv/lib/python3.12/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipywidgets) (9.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/andy/jupyter_venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/andy/jupyter_venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/andy/jupyter_venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y ninja-build cmake\n",
    "!pip install ipywidgets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EM8UTzsidgXe"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "k55ATwppBVZj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This part of code will skip all the un-necessary warnings which can occur during the execution of this project.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kHfXSmivkKPb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python==0.2.69 in /home/andy/jupyter_venv/lib/python3.12/site-packages (0.2.69)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from llama-cpp-python==0.2.69) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from llama-cpp-python==0.2.69) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from llama-cpp-python==0.2.69) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from llama-cpp-python==0.2.69) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.69) (3.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /home/andy/jupyter_venv/lib/python3.12/site-packages (0.31.4)\n",
      "Requirement already satisfied: filelock in /home/andy/jupyter_venv/lib/python3.12/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/andy/jupyter_venv/lib/python3.12/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from requests->huggingface_hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from requests->huggingface_hub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from requests->huggingface_hub) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "# Installation for GPU llama-cpp-python==0.2.69\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python==0.2.69\n",
    "# For downloading the models from HF Hub\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sq81SmRht8r_",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /home/andy/jupyter_venv/lib/python3.12/site-packages (0.4.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /home/andy/jupyter_venv/lib/python3.12/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/andy/jupyter_venv/lib/python3.12/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/andy/jupyter_venv/lib/python3.12/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/andy/jupyter_venv/lib/python3.12/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from evaluate) (0.31.4)\n",
      "Requirement already satisfied: packaging in /home/andy/jupyter_venv/lib/python3.12/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /home/andy/jupyter_venv/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: bert-score in /home/andy/jupyter_venv/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from bert-score) (2.7.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from bert-score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from bert-score) (4.52.2)\n",
      "Requirement already satisfied: numpy in /home/andy/jupyter_venv/lib/python3.12/site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/andy/jupyter_venv/lib/python3.12/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /home/andy/jupyter_venv/lib/python3.12/site-packages (from bert-score) (3.10.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: filelock in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (80.8.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.31.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from matplotlib->bert-score) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from matplotlib->bert-score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from matplotlib->bert-score) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from matplotlib->bert-score) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from requests->bert-score) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from requests->bert-score) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/andy/jupyter_venv/lib/python3.12/site-packages (from requests->bert-score) (2025.4.26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score) (12.6.20)\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 KB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 KB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (10.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.53.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers, bert-score\n",
      "Successfully installed bert-score-0.3.13 regex-2024.11.6 safetensors-0.5.2 tokenizers-0.21.0 transformers-4.48.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yBAX7X_aK3Ff"
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TsrUPUGTANTi"
   },
   "outputs": [],
   "source": [
    "# Basic Imports for Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "# from google.colab import drive\n",
    "import locale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdQdNav7AOtV",
    "tags": []
   },
   "source": [
    "### **Question 1: Importing Libaries and Mistral Model (3 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NO7TfAEiSxMR"
   },
   "source": [
    "- For the Mistral Model name or path and model basename, refer to the **Week 3 Additional Content: Prompt Engineering Fundamentals**\n",
    "- Code Notebook: Self-Consistency and Tree-of-Thought Prompting with Llama 2 and Mistral.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/blob/main/mistral-7b-instruct-v0.2.Q5_K_M.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cpQlIfeqAkvz"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e9c3ISlwftKB"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\" \n",
    "model_basename = \"mistral-7b-instruct-v0.2.Q5_K_M.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9iTSfdfVYHPC"
   },
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(\n",
    "    repo_id=model_name_or_path,\n",
    "    filename=model_basename\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VaTf7bc_X0jJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /home/andy/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 4050 Laptop GPU, compute capability 8.9, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    85.94 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  4807.05 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   512.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   296.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    16.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "lcpp_llm = Llama(\n",
    "        model_path=model_path,\n",
    "        n_threads=2,  # CPU cores\n",
    "        n_batch=512,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "        n_gpu_layers=43,  # Change this value based on your model and your GPU VRAM pool.\n",
    "        n_ctx=4096,  # Context window\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj8Gk-m1Iz1q",
    "tags": []
   },
   "source": [
    "# **Section 2: Text to Label generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6xcR3o2ga6p",
    "tags": []
   },
   "source": [
    "### **Question 2: Zero-Shot Prompting for Text Classification (5 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ8ual1jghmN",
    "tags": []
   },
   "source": [
    "##### **Q2.1: Define the Prompt Template, System Message, generate_prompt** **(2 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfNlwAXCBVZn"
   },
   "source": [
    "- Define a **system message** as a string and assign it to the variable system_message to generate product class.\n",
    "- Create a **zero shot prompt template** that incorporates the system message and user input.\n",
    "- Define **generate_prompt** function that takes both the system_message and user_input as arguments and formats them into a prompt template\n",
    "\n",
    "\n",
    "Write a Python function called **generate_mistral_response** that takes a single parameter, narrative, which represents the user's complain. Inside the function, you should perform the following tasks:\n",
    "\n",
    "\n",
    "- **Combine the system_message and narrative to create a prompt string using generate_prompt function.**\n",
    "\n",
    "*Generate a response from the Mistral model using the lcpp_llm instance with the following parameters:*\n",
    "\n",
    "- prompt should be the combined prompt string.\n",
    "- max_tokens should be set to 1200.\n",
    "- temperature should be set to 0.\n",
    "- top_p should be set to 0.95.\n",
    "- repeat_penalty should be set to 1.2.\n",
    "- top_k should be set to 50.\n",
    "- stop should be set as a list containing '/s'.\n",
    "- echo should be set to False.\n",
    "Extract and return the response text from the generated response.\n",
    "\n",
    "Don't forget to provide a value for the system_message variable before using it in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QIMDLp51ghGr"
   },
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant that classifies user complaints into one of the following product categories: credit_card, retail_banking, credit_reporting, mortgages_and_loans, or debt_collection. Respond only with the product category.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e24qaY7ug2CC"
   },
   "outputs": [],
   "source": [
    "zero_shot_prompt_template = \"\"\"[System Message]\\n{system_message}\\n\\n[User Complaint]\\n{user_input}\\n\\n[Response]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JKOyehERgy77"
   },
   "outputs": [],
   "source": [
    "def generate_prompt(system_message,user_input):\n",
    "    prompt = zero_shot_prompt_template.format(system_message=system_message, user_input=user_input)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3PJcu3dwg7FO"
   },
   "outputs": [],
   "source": [
    "def generate_mistral_response(input_text):\n",
    "\n",
    "    # Combine user_prompt and system_message to create the prompt\n",
    "    prompt = generate_prompt(system_message,input_text)\n",
    "\n",
    "    # Define the Llama model along with its parameters for generating a response\n",
    "    response = lcpp_llm(\n",
    "        prompt=prompt,\n",
    "        max_tokens=1200,\n",
    "        temperature=0,\n",
    "        top_p=0.95,\n",
    "        repeat_penalty=1.2,\n",
    "        top_k=50,\n",
    "        stop=[\"/s\"],\n",
    "        echo=False\n",
    "    )\n",
    "    # Extract and return the response text\n",
    "    response_text = response[\"choices\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SpTp2YQjBVZn"
   },
   "outputs": [],
   "source": [
    "# Load a CSV File containing Dataset of 500 products, narrative and summary (summary of narrative)\n",
    "data = pd.read_csv(\"Complaints_classification.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xhwItJrIhNta"
   },
   "outputs": [],
   "source": [
    "# Randomly select 30 rows\n",
    "new_data = data.sample(n=30, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>retail_banking</td>\n",
       "      <td>fraudulent charge totaling made capital one ch...</td>\n",
       "      <td>A fraudulent charge was made on the individual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>block except otherwise provided section consum...</td>\n",
       "      <td>The text outlines various stipulations regardi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>usaa master plan collect cancellation debt usa...</td>\n",
       "      <td>The input appears to be a complaint about USAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>block except otherwise provided section consum...</td>\n",
       "      <td>The text pertains to the stipulations and oper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>open account acct opened balance account acct ...</td>\n",
       "      <td>The input is about various accounts being open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>except otherwise provided section consumer rep...</td>\n",
       "      <td>This legal text details rules and regulations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mortgages_and_loans</td>\n",
       "      <td>trying close loan month provided income paymen...</td>\n",
       "      <td>The individual has been attempting to close a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>except otherwise provided section consumer rep...</td>\n",
       "      <td>This legislation requires that a consumer repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>block except otherwise provided section consum...</td>\n",
       "      <td>The section explains the rules and procedures ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>except otherwise provided section consumer rep...</td>\n",
       "      <td>The input text seems to discuss a law provisio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>true identity theft victim identity theft info...</td>\n",
       "      <td>The author has suffered from identity theft, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>block except otherwise provided section consum...</td>\n",
       "      <td>The inputs pertain to procedures and rules for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>except otherwise provided section consumer rep...</td>\n",
       "      <td>This section of the law mandates consumer repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mortgages_and_loans</td>\n",
       "      <td>family hardship paying mortgage applied modifi...</td>\n",
       "      <td>The family was experiencing hardship and could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>block except otherwise provided section consum...</td>\n",
       "      <td>This input is discussing the role and responsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>blockexcept otherwise provided section consume...</td>\n",
       "      <td>The text describes regulations on consumer rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>except otherwise provided section consumer rep...</td>\n",
       "      <td>This section mandates consumer reporting agenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>american express reduced credit limit without ...</td>\n",
       "      <td>The user has complained about American Express...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>true identity theft im member equifax data bre...</td>\n",
       "      <td>The individual's personal information was comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mortgages_and_loans</td>\n",
       "      <td>original mortgage taken sold loan servicing co...</td>\n",
       "      <td>The text revolves around a single mom who took...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>true identity theft transunion file report rep...</td>\n",
       "      <td>The individual is struggling with possible ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>usdoexxxx account reported abbreviated name fu...</td>\n",
       "      <td>The input is a series of complaints about inco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>several inquires credit file someone use ident...</td>\n",
       "      <td>The individual claims that their identity has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>conducted another investigation based new comp...</td>\n",
       "      <td>The text indicates an ongoing conflict related...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>purchase order day shipping amount receive pro...</td>\n",
       "      <td>The customer made a purchase order with an agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>except otherwise provided section consumer rep...</td>\n",
       "      <td>The text specifies the legal procedures and re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>true identity theft victim identity theft info...</td>\n",
       "      <td>The input is from an individual who is a victi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>true identity theft victim identity theft info...</td>\n",
       "      <td>The input discusses an individual who has disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>block except otherwise provided section consum...</td>\n",
       "      <td>This passage discusses the various provisions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>mother called remove authorized user never use...</td>\n",
       "      <td>The individual's mother requested to remove he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 product                                          narrative  \\\n",
       "167       retail_banking  fraudulent charge totaling made capital one ch...   \n",
       "169     credit_reporting  block except otherwise provided section consum...   \n",
       "461          credit_card  usaa master plan collect cancellation debt usa...   \n",
       "253     credit_reporting  block except otherwise provided section consum...   \n",
       "42      credit_reporting  open account acct opened balance account acct ...   \n",
       "369     credit_reporting  except otherwise provided section consumer rep...   \n",
       "26   mortgages_and_loans  trying close loan month provided income paymen...   \n",
       "377     credit_reporting  except otherwise provided section consumer rep...   \n",
       "238     credit_reporting  block except otherwise provided section consum...   \n",
       "374     credit_reporting  except otherwise provided section consumer rep...   \n",
       "140     credit_reporting  true identity theft victim identity theft info...   \n",
       "175     credit_reporting  block except otherwise provided section consum...   \n",
       "388     credit_reporting  except otherwise provided section consumer rep...   \n",
       "62   mortgages_and_loans  family hardship paying mortgage applied modifi...   \n",
       "256     credit_reporting  block except otherwise provided section consum...   \n",
       "332     credit_reporting  blockexcept otherwise provided section consume...   \n",
       "386     credit_reporting  except otherwise provided section consumer rep...   \n",
       "56           credit_card  american express reduced credit limit without ...   \n",
       "157     credit_reporting  true identity theft im member equifax data bre...   \n",
       "48   mortgages_and_loans  original mortgage taken sold loan servicing co...   \n",
       "163     credit_reporting  true identity theft transunion file report rep...   \n",
       "9       credit_reporting  usdoexxxx account reported abbreviated name fu...   \n",
       "441     credit_reporting  several inquires credit file someone use ident...   \n",
       "102          credit_card  conducted another investigation based new comp...   \n",
       "0            credit_card  purchase order day shipping amount receive pro...   \n",
       "364     credit_reporting  except otherwise provided section consumer rep...   \n",
       "139     credit_reporting  true identity theft victim identity theft info...   \n",
       "150     credit_reporting  true identity theft victim identity theft info...   \n",
       "173     credit_reporting  block except otherwise provided section consum...   \n",
       "463     credit_reporting  mother called remove authorized user never use...   \n",
       "\n",
       "                                               summary  \n",
       "167  A fraudulent charge was made on the individual...  \n",
       "169  The text outlines various stipulations regardi...  \n",
       "461  The input appears to be a complaint about USAA...  \n",
       "253  The text pertains to the stipulations and oper...  \n",
       "42   The input is about various accounts being open...  \n",
       "369  This legal text details rules and regulations ...  \n",
       "26   The individual has been attempting to close a ...  \n",
       "377  This legislation requires that a consumer repo...  \n",
       "238  The section explains the rules and procedures ...  \n",
       "374  The input text seems to discuss a law provisio...  \n",
       "140  The author has suffered from identity theft, w...  \n",
       "175  The inputs pertain to procedures and rules for...  \n",
       "388  This section of the law mandates consumer repo...  \n",
       "62   The family was experiencing hardship and could...  \n",
       "256  This input is discussing the role and responsi...  \n",
       "332  The text describes regulations on consumer rep...  \n",
       "386  This section mandates consumer reporting agenc...  \n",
       "56   The user has complained about American Express...  \n",
       "157  The individual's personal information was comp...  \n",
       "48   The text revolves around a single mom who took...  \n",
       "163  The individual is struggling with possible ide...  \n",
       "9    The input is a series of complaints about inco...  \n",
       "441  The individual claims that their identity has ...  \n",
       "102  The text indicates an ongoing conflict related...  \n",
       "0    The customer made a purchase order with an agr...  \n",
       "364  The text specifies the legal procedures and re...  \n",
       "139  The input is from an individual who is a victi...  \n",
       "150  The input discusses an individual who has disc...  \n",
       "173  This passage discusses the various provisions ...  \n",
       "463  The individual's mother requested to remove he...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-GrdMrVkaei",
    "tags": []
   },
   "source": [
    "##### **Q2.2: Create a new column in the DataFrame called 'mistral_response' and populate it with responses generated by applying the 'generate_mistral_response' function to each 'narrative' in the DataFrame and prepare the mistral_response_cleaned column using extract_category function** **(1 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BqEme1elh24Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /     6 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     408.95 ms /   284 tokens (    1.44 ms per token,   694.45 tokens per second)\n",
      "llama_print_timings:        eval time =     156.06 ms /     5 runs   (   31.21 ms per token,    32.04 tokens per second)\n",
      "llama_print_timings:       total time =     576.36 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_card\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /     7 runs   (    0.20 ms per token,  5124.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     431.81 ms /   505 tokens (    0.86 ms per token,  1169.50 tokens per second)\n",
      "llama_print_timings:        eval time =     187.49 ms /     6 runs   (   31.25 ms per token,    32.00 tokens per second)\n",
      "llama_print_timings:       total time =     632.48 ms /   511 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.22 ms /     6 runs   (    0.20 ms per token,  4909.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.97 ms /   182 tokens (    1.22 ms per token,   819.95 tokens per second)\n",
      "llama_print_timings:        eval time =     160.22 ms /     5 runs   (   32.04 ms per token,    31.21 tokens per second)\n",
      "llama_print_timings:       total time =     392.25 ms /   187 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "debt_collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /     7 runs   (    0.19 ms per token,  5185.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     429.15 ms /   505 tokens (    0.85 ms per token,  1176.73 tokens per second)\n",
      "llama_print_timings:        eval time =     186.24 ms /     6 runs   (   31.04 ms per token,    32.22 tokens per second)\n",
      "llama_print_timings:       total time =     626.45 ms /   511 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.23 ms /     7 runs   (    0.18 ms per token,  5714.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.41 ms /    74 tokens (    2.53 ms per token,   394.85 tokens per second)\n",
      "llama_print_timings:        eval time =     188.47 ms /     6 runs   (   31.41 ms per token,    31.84 tokens per second)\n",
      "llama_print_timings:       total time =     387.44 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "retail_banking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /     7 runs   (    0.18 ms per token,  5520.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     377.24 ms /   420 tokens (    0.90 ms per token,  1113.35 tokens per second)\n",
      "llama_print_timings:        eval time =     185.79 ms /     6 runs   (   30.96 ms per token,    32.30 tokens per second)\n",
      "llama_print_timings:       total time =     575.62 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /    11 runs   (    0.19 ms per token,  5291.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.05 ms /    87 tokens (    2.18 ms per token,   457.78 tokens per second)\n",
      "llama_print_timings:        eval time =     309.85 ms /    10 runs   (   30.98 ms per token,    32.27 tokens per second)\n",
      "llama_print_timings:       total time =     518.14 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mortgages_and_loans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /     7 runs   (    0.19 ms per token,  5227.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     378.68 ms /   420 tokens (    0.90 ms per token,  1109.11 tokens per second)\n",
      "llama_print_timings:        eval time =     186.19 ms /     6 runs   (   31.03 ms per token,    32.23 tokens per second)\n",
      "llama_print_timings:       total time =     576.48 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /     7 runs   (    0.18 ms per token,  5524.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     383.01 ms /   432 tokens (    0.89 ms per token,  1127.92 tokens per second)\n",
      "llama_print_timings:        eval time =     196.59 ms /     6 runs   (   32.77 ms per token,    30.52 tokens per second)\n",
      "llama_print_timings:       total time =     591.10 ms /   438 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /     7 runs   (    0.19 ms per token,  5223.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     376.38 ms /   420 tokens (    0.90 ms per token,  1115.89 tokens per second)\n",
      "llama_print_timings:        eval time =     184.64 ms /     6 runs   (   30.77 ms per token,    32.50 tokens per second)\n",
      "llama_print_timings:       total time =     571.72 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /     7 runs   (    0.20 ms per token,  5007.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     210.70 ms /   147 tokens (    1.43 ms per token,   697.66 tokens per second)\n",
      "llama_print_timings:        eval time =     188.04 ms /     6 runs   (   31.34 ms per token,    31.91 tokens per second)\n",
      "llama_print_timings:       total time =     411.90 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     7 runs   (    0.31 ms per token,  3177.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     430.03 ms /   511 tokens (    0.84 ms per token,  1188.28 tokens per second)\n",
      "llama_print_timings:        eval time =     208.12 ms /     6 runs   (   34.69 ms per token,    28.83 tokens per second)\n",
      "llama_print_timings:       total time =     655.49 ms /   517 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /     7 runs   (    0.18 ms per token,  5464.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     373.78 ms /   420 tokens (    0.89 ms per token,  1123.65 tokens per second)\n",
      "llama_print_timings:        eval time =     188.54 ms /     6 runs   (   31.42 ms per token,    31.82 tokens per second)\n",
      "llama_print_timings:       total time =     573.05 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /    11 runs   (    0.20 ms per token,  4928.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.83 ms /   232 tokens (    1.08 ms per token,   924.95 tokens per second)\n",
      "llama_print_timings:        eval time =     312.35 ms /    10 runs   (   31.23 ms per token,    32.02 tokens per second)\n",
      "llama_print_timings:       total time =     581.85 ms /   242 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mortgages_and_loans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /     7 runs   (    0.20 ms per token,  4996.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     433.02 ms /   511 tokens (    0.85 ms per token,  1180.08 tokens per second)\n",
      "llama_print_timings:        eval time =     189.64 ms /     6 runs   (   31.61 ms per token,    31.64 tokens per second)\n",
      "llama_print_timings:       total time =     634.41 ms /   517 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /     7 runs   (    0.18 ms per token,  5443.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     385.84 ms /   438 tokens (    0.88 ms per token,  1135.19 tokens per second)\n",
      "llama_print_timings:        eval time =     188.04 ms /     6 runs   (   31.34 ms per token,    31.91 tokens per second)\n",
      "llama_print_timings:       total time =     586.39 ms /   444 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /     7 runs   (    0.18 ms per token,  5443.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     378.63 ms /   420 tokens (    0.90 ms per token,  1109.25 tokens per second)\n",
      "llama_print_timings:        eval time =     188.00 ms /     6 runs   (   31.33 ms per token,    31.91 tokens per second)\n",
      "llama_print_timings:       total time =     578.27 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /     6 runs   (    0.20 ms per token,  5037.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     238.22 ms /   193 tokens (    1.23 ms per token,   810.16 tokens per second)\n",
      "llama_print_timings:        eval time =     161.98 ms /     5 runs   (   32.40 ms per token,    30.87 tokens per second)\n",
      "llama_print_timings:       total time =     411.11 ms /   198 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_card\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /     7 runs   (    0.21 ms per token,  4710.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.50 ms /   139 tokens (    1.49 ms per token,   669.89 tokens per second)\n",
      "llama_print_timings:        eval time =     186.33 ms /     6 runs   (   31.05 ms per token,    32.20 tokens per second)\n",
      "llama_print_timings:       total time =     406.48 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    11 runs   (    0.22 ms per token,  4645.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     310.24 ms /   358 tokens (    0.87 ms per token,  1153.93 tokens per second)\n",
      "llama_print_timings:        eval time =     313.66 ms /    10 runs   (   31.37 ms per token,    31.88 tokens per second)\n",
      "llama_print_timings:       total time =     643.35 ms /   368 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mortgages_and_loans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /     7 runs   (    0.18 ms per token,  5604.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.58 ms /    72 tokens (    2.58 ms per token,   387.98 tokens per second)\n",
      "llama_print_timings:        eval time =     185.55 ms /     6 runs   (   30.93 ms per token,    32.34 tokens per second)\n",
      "llama_print_timings:       total time =     382.54 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /     7 runs   (    0.20 ms per token,  4929.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     302.55 ms /   336 tokens (    0.90 ms per token,  1110.57 tokens per second)\n",
      "llama_print_timings:        eval time =     184.35 ms /     6 runs   (   30.73 ms per token,    32.55 tokens per second)\n",
      "llama_print_timings:       total time =     499.09 ms /   342 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /     7 runs   (    0.19 ms per token,  5192.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.56 ms /   111 tokens (    1.76 ms per token,   567.60 tokens per second)\n",
      "llama_print_timings:        eval time =     187.75 ms /     6 runs   (   31.29 ms per token,    31.96 tokens per second)\n",
      "llama_print_timings:       total time =     396.11 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /     7 runs   (    0.19 ms per token,  5239.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     208.22 ms /   133 tokens (    1.57 ms per token,   638.75 tokens per second)\n",
      "llama_print_timings:        eval time =     183.57 ms /     6 runs   (   30.60 ms per token,    32.68 tokens per second)\n",
      "llama_print_timings:       total time =     402.53 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.32 ms /     7 runs   (    0.19 ms per token,  5291.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     290.51 ms /   290 tokens (    1.00 ms per token,   998.24 tokens per second)\n",
      "llama_print_timings:        eval time =     184.44 ms /     6 runs   (   30.74 ms per token,    32.53 tokens per second)\n",
      "llama_print_timings:       total time =     487.21 ms /   296 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "retail_banking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.24 ms /     7 runs   (    0.18 ms per token,  5649.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     377.04 ms /   420 tokens (    0.90 ms per token,  1113.94 tokens per second)\n",
      "llama_print_timings:        eval time =     186.55 ms /     6 runs   (   31.09 ms per token,    32.16 tokens per second)\n",
      "llama_print_timings:       total time =     575.26 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /     7 runs   (    0.18 ms per token,  5622.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.51 ms /   103 tokens (    1.88 ms per token,   532.28 tokens per second)\n",
      "llama_print_timings:        eval time =     187.03 ms /     6 runs   (   31.17 ms per token,    32.08 tokens per second)\n",
      "llama_print_timings:       total time =     391.71 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.44 ms /     7 runs   (    0.21 ms per token,  4861.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     213.35 ms /   152 tokens (    1.40 ms per token,   712.46 tokens per second)\n",
      "llama_print_timings:        eval time =     184.77 ms /     6 runs   (   30.79 ms per token,    32.47 tokens per second)\n",
      "llama_print_timings:       total time =     410.39 ms /   158 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /     7 runs   (    0.20 ms per token,  5083.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     433.55 ms /   505 tokens (    0.86 ms per token,  1164.81 tokens per second)\n",
      "llama_print_timings:        eval time =     191.54 ms /     6 runs   (   31.92 ms per token,    31.32 tokens per second)\n",
      "llama_print_timings:       total time =     636.36 ms /   511 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /     7 runs   (    0.20 ms per token,  5032.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.09 ms /    95 tokens (    2.02 ms per token,   494.57 tokens per second)\n",
      "llama_print_timings:        eval time =     182.99 ms /     6 runs   (   30.50 ms per token,    32.79 tokens per second)\n",
      "llama_print_timings:       total time =     385.91 ms /   101 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    }
   ],
   "source": [
    "# example - new_data['mistral_response'] = new_data['narrative'].apply(lambda x:______ )\n",
    "#new_data['mistral_response'] = new_data['narrative'].apply(lambda x: \"_____\")\n",
    "\n",
    "new_data['mistral_response'] = new_data['narrative'].apply(lambda x: generate_mistral_response(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "K1CBbpD3m_rf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167            \\ncredit_card\n",
       "169       \\ncredit_reporting\n",
       "461        \\ndebt_collection\n",
       "253       \\ncredit_reporting\n",
       "42          \\nretail_banking\n",
       "369       \\ncredit_reporting\n",
       "26     \\nmortgages_and_loans\n",
       "377       \\ncredit_reporting\n",
       "238       \\ncredit_reporting\n",
       "374       \\ncredit_reporting\n",
       "140       \\ncredit_reporting\n",
       "175       \\ncredit_reporting\n",
       "388       \\ncredit_reporting\n",
       "62     \\nmortgages_and_loans\n",
       "256       \\ncredit_reporting\n",
       "332       \\ncredit_reporting\n",
       "386       \\ncredit_reporting\n",
       "56             \\ncredit_card\n",
       "157       \\ncredit_reporting\n",
       "48     \\nmortgages_and_loans\n",
       "163       \\ncredit_reporting\n",
       "9         \\ncredit_reporting\n",
       "441       \\ncredit_reporting\n",
       "102       \\ncredit_reporting\n",
       "0           \\nretail_banking\n",
       "364       \\ncredit_reporting\n",
       "139       \\ncredit_reporting\n",
       "150       \\ncredit_reporting\n",
       "173       \\ncredit_reporting\n",
       "463       \\ncredit_reporting\n",
       "Name: mistral_response, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['mistral_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "10Bulypzkwjt"
   },
   "outputs": [],
   "source": [
    "def extract_category(text):\n",
    "    # Define the regex pattern to match \"category:\" or \"Category:\" followed by a word\n",
    "    pattern = r'category:\\s*(\\w+)'  # The pattern itself remains the same\n",
    "\n",
    "    # Use re.search with the re.IGNORECASE flag to make it case-insensitive\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "\n",
    "    # If a match is found, return the captured group, else return None\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        pattern1 = r'(credit_card|retail_banking|credit_reporting|mortgages_and_loans|debt_collection)'\n",
    "        match = re.search(pattern1, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group()\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "w-REbjsCnhaq"
   },
   "outputs": [],
   "source": [
    "# example - new_data['mistral_response_cleaned'] = new_data['narrative'].apply(lambda x:______ )\n",
    "new_data['mistral_response_cleaned'] = new_data['mistral_response'].apply(lambda x:extract_category(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UGfRZ7dUw4tr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "      <th>summary</th>\n",
       "      <th>mistral_response</th>\n",
       "      <th>mistral_response_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>retail_banking</td>\n",
       "      <td>fraudulent charge totaling made capital one ch...</td>\n",
       "      <td>A fraudulent charge was made on the individual...</td>\n",
       "      <td>\\ncredit_card</td>\n",
       "      <td>credit_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>block except otherwise provided section consum...</td>\n",
       "      <td>The text outlines various stipulations regardi...</td>\n",
       "      <td>\\ncredit_reporting</td>\n",
       "      <td>credit_reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>usaa master plan collect cancellation debt usa...</td>\n",
       "      <td>The input appears to be a complaint about USAA...</td>\n",
       "      <td>\\ndebt_collection</td>\n",
       "      <td>debt_collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>block except otherwise provided section consum...</td>\n",
       "      <td>The text pertains to the stipulations and oper...</td>\n",
       "      <td>\\ncredit_reporting</td>\n",
       "      <td>credit_reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>open account acct opened balance account acct ...</td>\n",
       "      <td>The input is about various accounts being open...</td>\n",
       "      <td>\\nretail_banking</td>\n",
       "      <td>retail_banking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              product                                          narrative  \\\n",
       "167    retail_banking  fraudulent charge totaling made capital one ch...   \n",
       "169  credit_reporting  block except otherwise provided section consum...   \n",
       "461       credit_card  usaa master plan collect cancellation debt usa...   \n",
       "253  credit_reporting  block except otherwise provided section consum...   \n",
       "42   credit_reporting  open account acct opened balance account acct ...   \n",
       "\n",
       "                                               summary    mistral_response  \\\n",
       "167  A fraudulent charge was made on the individual...       \\ncredit_card   \n",
       "169  The text outlines various stipulations regardi...  \\ncredit_reporting   \n",
       "461  The input appears to be a complaint about USAA...   \\ndebt_collection   \n",
       "253  The text pertains to the stipulations and oper...  \\ncredit_reporting   \n",
       "42   The input is about various accounts being open...    \\nretail_banking   \n",
       "\n",
       "    mistral_response_cleaned  \n",
       "167              credit_card  \n",
       "169         credit_reporting  \n",
       "461          debt_collection  \n",
       "253         credit_reporting  \n",
       "42            retail_banking  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9t6gsZVsL2b",
    "tags": []
   },
   "source": [
    "##### **Q2.3: Calculate the F1 score** **(1 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "CeUoZb4ttDCL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score for 'product' and 'mistral_response'\n",
    "f1 =  f1_score(new_data['product'], new_data['mistral_response'],average='micro')\n",
    "\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ynzQvTi8tCcp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score for 'product' and 'mistral_response_cleaned'\n",
    "f2 = f1_score(new_data['product'], new_data['mistral_response_cleaned'], average='micro')\n",
    "print(f'F1 Score: {f2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "803ZuG7OtSSj",
    "tags": []
   },
   "source": [
    "##### **Q2.4: Explain the difference in F1 scores between mistral_response and mistral_response_cleaned.** **(1 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5znlDvcggYm"
   },
   "source": [
    "#### mistral_response_cleaned has a higher F1 score because it extracts only the predicted category, removing extra text from the full mistral_response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0YUCSXAnx3y",
    "tags": []
   },
   "source": [
    "### **Question 3: Few-Shot Prompting for Text Classification (7 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgxdRjW_wHId",
    "tags": []
   },
   "source": [
    "##### **Q3.1: Prepare examples for a few-shot prompt, formulate the prompt, and generate the Mistral response. (5 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPuH7_ravBtS"
   },
   "source": [
    "**Generate a set of gold examples by randomly selecting 10 instances of user_input and assistant_output from dataset ensuring a balanced representation with 2 examples from each class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "iO9Wj19_n_LO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'narrative': 'called request new york state covid relief plan day interest fee waived amex provided relief leading late payment amex refused honor relief day gap insists charging late fee', 'product': 'credit_card'}\n",
      "Examples Set Shape: (10, 3)\n",
      "Gold Examples Shape: (490, 3)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "review_1 = data[data['product'] == 'credit_card']\n",
    "review_2 = data[data['product'] == 'retail_banking']\n",
    "review_3 = data[data['product'] == 'credit_reporting']\n",
    "review_4 = data[data['product'] == 'mortgages_and_loans']\n",
    "review_5 = data[data['product'] == 'debt_collection']\n",
    "\n",
    "# Sample 2 examples for each category\n",
    "examples_1 = review_1.sample(2, random_state=40)\n",
    "examples_2 = review_2.sample(2, random_state=40)\n",
    "examples_3 = review_3.sample(2, random_state=40)\n",
    "examples_4 = review_4.sample(2, random_state=40)\n",
    "examples_5 = review_5.sample(2, random_state=40)\n",
    "\n",
    "# Concatenate examples for few shot prompting\n",
    "examples_df = pd.concat([examples_1,examples_2,examples_3,examples_4,examples_5 ])\n",
    "\n",
    "# Create the training set by excluding examples\n",
    "gold_examples_df = data.drop(index=examples_df.index)\n",
    "\n",
    "# Convert examples to JSON\n",
    "columns_to_select = ['narrative', 'product']\n",
    "examples_json = examples_df[columns_to_select].to_json(orient='records')\n",
    "\n",
    "# Print the first record from the JSON\n",
    "print(json.loads(examples_json)[0])\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Examples Set Shape:\", examples_df.shape)\n",
    "print(\"Gold Examples Shape:\", gold_examples_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1i8taCkTwqOl"
   },
   "source": [
    "- Define your **system_message**.\n",
    "- Define **first_turn_template**, **example_template** and **prediction template**\n",
    "- **create few shot prompt** using gold examples and system_message\n",
    "- Randomly select 30 rows from test_df as test_data\n",
    "- Create **mistral_response** with **mistral_response_cleaned** columns for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "iPzpBeWmzSIH"
   },
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant that classifies user complaints into one of the following product categories: credit_card, retail_banking, credit_reporting, mortgages_and_loans, or debt_collection. Respond only with the product category.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2bPjQJs_zRoo"
   },
   "outputs": [],
   "source": [
    "\n",
    "first_turn_template = \"\"\"[System Message]\n",
    "{system_message}\n",
    "\n",
    "[User Complaint]\n",
    "{user_input}\n",
    "\n",
    "[Assistant Response]\n",
    "{assistant_output}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Template for subsequent examples\n",
    "examples_template = \"\"\"[User Complaint]\n",
    "{user_input}\n",
    "\n",
    "[Assistant Response]\n",
    "{assistant_output}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prediction_template = \"\"\"[User Complaint]\n",
    "{user_input}\n",
    "\n",
    "[Assistant Response]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "X07_kNji0vTp"
   },
   "outputs": [],
   "source": [
    "def create_few_shot_prompt(system_message, examples_df):\n",
    "\n",
    "    \"\"\"\n",
    "    Return a prompt message in the format expected by Mistral 7b.\n",
    "    10 examples are selected randomly as golden examples to form the\n",
    "    few-shot prompt.\n",
    "    We then loop through each example and parse the narrative as the user message\n",
    "    and the product as the assistant message.\n",
    "\n",
    "    Args:\n",
    "        system_message (str): system message with instructions for classification\n",
    "        examples(DataFrame): A DataFrame with examples (product + narrative + summary)\n",
    "        to form the few-shot prompt.\n",
    "\n",
    "    Output:\n",
    "        few_shot_prompt (str): A prompt string in the Mistral format\n",
    "    \"\"\"\n",
    "\n",
    "    few_shot_prompt = ''\n",
    "\n",
    "    columns_to_select = ['narrative', 'product']\n",
    "    examples = (\n",
    "        examples_df.loc[:, columns_to_select].to_json(orient='records')\n",
    "    )\n",
    "\n",
    "    for idx, example in enumerate(json.loads(examples)):\n",
    "        user_input_example = example['narrative']\n",
    "        assistant_output_example = example['product']\n",
    "\n",
    "        if idx == 0:\n",
    "            few_shot_prompt += first_turn_template.format(\n",
    "                system_message=system_message,\n",
    "                user_input=user_input_example,\n",
    "                assistant_output=assistant_output_example\n",
    "            )\n",
    "        else:\n",
    "            few_shot_prompt += examples_template.format(\n",
    "                user_input=user_input_example,\n",
    "                assistant_output=assistant_output_example\n",
    "            )\n",
    "\n",
    "    return few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "yHfPlD9o1G7M"
   },
   "outputs": [],
   "source": [
    "few_shot_prompt = create_few_shot_prompt(system_message, examples_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uPsvRQrC0Afr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System Message]\n",
      "You are a helpful assistant that classifies user complaints into one of the following product categories: credit_card, retail_banking, credit_reporting, mortgages_and_loans, or debt_collection. Respond only with the product category.\n",
      "\n",
      "[User Complaint]\n",
      "called request new york state covid relief plan day interest fee waived amex provided relief leading late payment amex refused honor relief day gap insists charging late fee\n",
      "\n",
      "[Assistant Response]\n",
      "credit_card\n",
      "\n",
      "[User Complaint]\n",
      "dispute case card ending usaa credit card merchant name transaction date transaction amount disputed amount dispute case card ending usaa credit card merchant name transaction date transaction amount disputed amount dispute making purchase credit card usaa two separate transaction merchant purchased trip cancelled told apply refund apply refund however company give refund back filed dispute credit agency help dispute account follow dispute policy state service provided customer right receive full refund impact credit negative way increasing credit balance decreasing credit score currently refinancing house also effecting financial relate\n",
      "\n",
      "[Assistant Response]\n",
      "credit_card\n",
      "\n",
      "[User Complaint]\n",
      "ref cfpb case acct ending complaint duplicate complaint would like cfpb take notice well fargo bank address problem specifically stated filed fraud claim online account access frozen spoke two separate fraud rep go branch unlocked time informed another banker situation latest response proven following regulation treating unfairly specifically asked whether investigation commenced spoke fraud rep phone asked question well fargo stating ca find claim research mine proof within wf data quite sure contact banker called behalf get freeze removed validation also state account closed due prolonged overdraft specific issue also never addressed considering several time pointed fraud account investigated investigation completed long account closed per provision regulation e well fargo clearly ignored reiterate premise complaint begin also failed address could find claim mine one rep told claim called find information conversation took place recorded line might add also failed address whether spoke see could remember coming providing proof fraud promised fact deliver branch manager amnesia meeting apparently lost proof assured forwarded fraud behalf front witness brought response also mention indicated transaction disputing claim open record never stated filed claim either month idea fraud even taking place upon discovering proof fraud immediately called branch spoke believe asked help moreover know specific transaction amount mentioned recording gave wf personnel proof mentioned branch manager printed statement went transaction branch manager pointed matched alleged amount stolen specifically pointed withdraw branch two withdraws totaling late several casino transaction stated numerous complaint filed well fargo stating claim found regulation e specifically state timing content financial institution shall comply requirement section respect oral written notice error consumer official interpretation b timing content show received institution later day institution sends periodic statement provides passbook documentation required alleged error first reflected ii enables institution identify consumer name account number iii indicates consumer belief error exists includes extent possible type date amount error except request described paragraph vii section would like point wf informed fraud around complies also want point one fraud rep froze account complies ii iii also consumer compliance told rep found evidence gave information knew gave information extent possible amount mentioned recording thought responsible would also like add wf requested information writing even though initial claim filed month earlier nevertheless regulation state regarding written notice written confirmation financial institution may require consumer give written confirmation error within business day oral notice institution requires written confirmation shall inform consumer requirement provide address confirmation must sent consumer give oral notification also complied response well fargo address comment infamous fiasco making victim customer pointed delivering promise making thing right customer cfpb database well consumer advocacy organization accept publicly post complaint prove much improve state thing many many customer wf bank filed fraud claim even stretch imagination conclude fraud occur account wf still denied claim ca speak claim told truth contacted law enforcement complied request got wf asked help victimized victimization completely ignored police turn provided responsible impunity lack interest enthusiasm assist male filed claim perpetrator victimization free took full advantage aware unusual case however recorded conversation perpetrator crime leave doubt victimized specifically state tape already stole dollar social security award even used term social security would like move offered beginning give wf money would take recording analyzed forensic expert audio video recording need validated need closure lying delusional trying run scam provided police video footage victimized real time happens wf could knight shining armor exposed unheard type theft lack exposure study allowed successful opinion several video audio clip still prove took place even went see patient expert opinion validated victimization real really taken place well fargo made situation much harder deal follow regulation rapist might gotten away getting paid handsomely victimize like movie nobody help perhaps man man likely accused law enforcement involved victimization prior situation occurring investigation completed year ago still fighting right wf bank following error resolution procedure refunded stolen money back long ago still hopeful right thing letting go nothing wrong anything deserve victimization whether wf want believe provided proof failed follow federal regulation regarding error resolution procedure must know another lengthy delay really insulting point could find claim back certainly became aware point first contact day given amount correspondence complaint phone call written account taken place law say limited liability asking someone anyone enforce harmed enough hope someone agrees help\n",
      "\n",
      "[Assistant Response]\n",
      "retail_banking\n",
      "\n",
      "[User Complaint]\n",
      "app access checking account round credit card purchase invest new worked great last year u deny access\n",
      "\n",
      "[Assistant Response]\n",
      "retail_banking\n",
      "\n",
      "[User Complaint]\n",
      "tx tx xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx fraudulent application submitted name identity used without consent fraudulently obtain good service extend credit without first contacting personally verifying application information day evening\n",
      "\n",
      "[Assistant Response]\n",
      "credit_reporting\n",
      "\n",
      "[User Complaint]\n",
      "true identity theft victim identity theft information listed appears credit report relate transaction made result identity theft also victim equifax data breach several account credit report mine listed report number file number equifax report confirmation account number collection opened account number collection opened account number opened account number date opened xxxxxx please block information credit report pursuant section fair credit reporting act send required notification furnishers information thank much safe wear mask stay home\n",
      "\n",
      "[Assistant Response]\n",
      "credit_reporting\n",
      "\n",
      "[User Complaint]\n",
      "current loan got deferment paid back credit history yet lost job due covid therefore asking original bank ally lower rate allow lower payment every bank offering applied full page document today still reply called time portal representative tell use work call get told need one piece documentation time refuse allow speak even email underwriter yet applying original mortgage one dedicated rep could communicate rep told yes document would word within day waited till called told go website told work read underwriter note documentation old would start\n",
      "\n",
      "[Assistant Response]\n",
      "mortgages_and_loans\n",
      "\n",
      "[User Complaint]\n",
      "declared chapter bankruptcy granted bankruptcy court private student loan peak private loan included bankruptcy peak loan notified bankruptcy sure court well receiving phone call peak informed attorney contacted peak behalf end phone call worked least temporary attended graduating even loan peak wiped clean part bankruptcy cfpb state district columbia ordered peak stop collection cancel outstanding loan owns relating request credit reporting bureau delete peak entry well done either already contacted attorney like file formal complaint people harassing long\n",
      "\n",
      "[Assistant Response]\n",
      "mortgages_and_loans\n",
      "\n",
      "[User Complaint]\n",
      "went store wife buy salesman offerred u special joing special buying special would install system free would pay basic service considered young son watch cartoon basic service watch premium service explained first bill would reflect fee totaling pay would rebated service would thereafter installed system first bill received almost twice agreed upon called dispute sitting hold hour waiting various people help apologized said would corrected next bill next bill came also twice represented called dispute sat hold hour point said could discus account delinquent paid amount month told amount would corrected next bill next bill came even higher called complain sat hold hour told would escalated corrected told could correct constant billing error take back equipment cancel service apologized profusely assured time would corrected never next bill came like others twice represented sat hold hour told could discus account delinquent paid amount month told amount would corrected next bill next bill came finally month correct amount would last month next one came double back xxxxmonth past due new regular monthly job waiting hold hour time feeling like straight defrauded shaken every month needing multiple long call contacted speak manager defrauded filled dispute form told could help contract actually division especially need contact contacted told exact opposite phone call hour plus phone call disconnected transferred hung afte waiting ended told could help call given final notice service would terminated owed double charged double paying almost year point called another call told come pick equipment defrauded want service anymore said would send someone pick equipment usual never said one showed disconnected service said owed somehow day later bank checked credit shock showed collection defrauded also ruined credit\n",
      "\n",
      "[Assistant Response]\n",
      "debt_collection\n",
      "\n",
      "[User Complaint]\n",
      "wf crd svc claim owe account opened result identity theft informed company also provided police report refuse take credit charged amount effecting credit hindering first time home buyer claim account opened\n",
      "\n",
      "[Assistant Response]\n",
      "debt_collection\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "EmTmY2oq3PRv"
   },
   "outputs": [],
   "source": [
    "def generate_prompt(few_shot_prompt,new_review):\n",
    "    prompt =  few_shot_prompt + prediction_template.format(user_input=new_review)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "GKrndCFRCJhK"
   },
   "outputs": [],
   "source": [
    "def generate_mistral_response(support_ticket_text):\n",
    "\n",
    "    # Combine user_prompt and system_message to create the prompt\n",
    "    prompt = generate_prompt(system_message,support_ticket_text)\n",
    "\n",
    "    # Define the Llama model along with its parameters for generating a response\n",
    "  # Call the Llama model to generate a response\n",
    "    response = lcpp_llm(\n",
    "        prompt=prompt,\n",
    "        max_tokens=1200,\n",
    "        temperature=0,\n",
    "        top_p=0.95,\n",
    "        repeat_penalty=1.2,\n",
    "        top_k=50,\n",
    "        stop=[\"/s\"],\n",
    "        echo=False\n",
    "    )\n",
    "\n",
    "    # Extract and return the response text\n",
    "    response_text = response[\"choices\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "FKYOjm7LDLJj"
   },
   "outputs": [],
   "source": [
    "# Randomly select 50 rows from gold_examples\n",
    "new_data = gold_examples_df.sample(n=50, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "JdsjoaP4DXIk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /     7 runs   (    0.20 ms per token,  4936.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.01 ms /   719 tokens (    0.96 ms per token,  1043.53 tokens per second)\n",
      "llama_print_timings:        eval time =     193.70 ms /     6 runs   (   32.28 ms per token,    30.98 tokens per second)\n",
      "llama_print_timings:       total time =     898.20 ms /   725 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mortgage_and_loans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     5 runs   (    0.18 ms per token,  5636.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     386.02 ms /   434 tokens (    0.89 ms per token,  1124.29 tokens per second)\n",
      "llama_print_timings:        eval time =     125.88 ms /     4 runs   (   31.47 ms per token,    31.78 tokens per second)\n",
      "llama_print_timings:       total time =     520.08 ms /   438 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /     7 runs   (    0.20 ms per token,  4919.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     163.30 ms /    19 tokens (    8.59 ms per token,   116.35 tokens per second)\n",
      "llama_print_timings:        eval time =     183.32 ms /     6 runs   (   30.55 ms per token,    32.73 tokens per second)\n",
      "llama_print_timings:       total time =     359.85 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     5 runs   (    0.18 ms per token,  5470.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     377.83 ms /   422 tokens (    0.90 ms per token,  1116.89 tokens per second)\n",
      "llama_print_timings:        eval time =     124.00 ms /     4 runs   (   31.00 ms per token,    32.26 tokens per second)\n",
      "llama_print_timings:       total time =     509.96 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     5 runs   (    0.19 ms per token,  5376.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     386.53 ms /   434 tokens (    0.89 ms per token,  1122.81 tokens per second)\n",
      "llama_print_timings:        eval time =     137.63 ms /     4 runs   (   34.41 ms per token,    29.06 tokens per second)\n",
      "llama_print_timings:       total time =     532.56 ms /   438 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     5 runs   (    0.18 ms per token,  5411.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.32 ms /    86 tokens (    2.31 ms per token,   433.64 tokens per second)\n",
      "llama_print_timings:        eval time =     125.41 ms /     4 runs   (   31.35 ms per token,    31.90 tokens per second)\n",
      "llama_print_timings:       total time =     332.06 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     5 runs   (    0.18 ms per token,  5605.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     381.39 ms /   422 tokens (    0.90 ms per token,  1106.49 tokens per second)\n",
      "llama_print_timings:        eval time =     126.52 ms /     4 runs   (   31.63 ms per token,    31.61 tokens per second)\n",
      "llama_print_timings:       total time =     515.55 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /     6 runs   (    0.20 ms per token,  5063.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     176.45 ms /    46 tokens (    3.84 ms per token,   260.70 tokens per second)\n",
      "llama_print_timings:        eval time =     154.86 ms /     5 runs   (   30.97 ms per token,    32.29 tokens per second)\n",
      "llama_print_timings:       total time =     341.87 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "debt_collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     4 runs   (    0.21 ms per token,  4796.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.55 ms /    68 tokens (    2.76 ms per token,   362.58 tokens per second)\n",
      "llama_print_timings:        eval time =      97.57 ms /     3 runs   (   32.52 ms per token,    30.75 tokens per second)\n",
      "llama_print_timings:       total time =     292.15 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " debt_collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     5 runs   (    0.19 ms per token,  5279.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     390.07 ms /   439 tokens (    0.89 ms per token,  1125.44 tokens per second)\n",
      "llama_print_timings:        eval time =     125.39 ms /     4 runs   (   31.35 ms per token,    31.90 tokens per second)\n",
      "llama_print_timings:       total time =     523.67 ms /   443 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     5 runs   (    0.19 ms per token,  5159.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     380.40 ms /   422 tokens (    0.90 ms per token,  1109.36 tokens per second)\n",
      "llama_print_timings:        eval time =     123.73 ms /     4 runs   (   30.93 ms per token,    32.33 tokens per second)\n",
      "llama_print_timings:       total time =     512.81 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     5 runs   (    0.19 ms per token,  5330.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     178.27 ms /    54 tokens (    3.30 ms per token,   302.91 tokens per second)\n",
      "llama_print_timings:        eval time =     125.76 ms /     4 runs   (   31.44 ms per token,    31.81 tokens per second)\n",
      "llama_print_timings:       total time =     311.89 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /     7 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     178.29 ms /    54 tokens (    3.30 ms per token,   302.87 tokens per second)\n",
      "llama_print_timings:        eval time =     184.31 ms /     6 runs   (   30.72 ms per token,    32.55 tokens per second)\n",
      "llama_print_timings:       total time =     373.29 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     5 runs   (    0.18 ms per token,  5458.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     383.78 ms /   422 tokens (    0.91 ms per token,  1099.58 tokens per second)\n",
      "llama_print_timings:        eval time =     125.54 ms /     4 runs   (   31.39 ms per token,    31.86 tokens per second)\n",
      "llama_print_timings:       total time =     516.92 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /    12 runs   (    0.20 ms per token,  5126.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.79 ms /   245 tokens (    1.04 ms per token,   957.82 tokens per second)\n",
      "llama_print_timings:        eval time =     340.28 ms /    11 runs   (   30.93 ms per token,    32.33 tokens per second)\n",
      "llama_print_timings:       total time =     616.43 ms /   256 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_mortgages_and_loans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /     5 runs   (    0.20 ms per token,  5020.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     436.64 ms /   512 tokens (    0.85 ms per token,  1172.59 tokens per second)\n",
      "llama_print_timings:        eval time =     156.72 ms /     5 runs   (   31.34 ms per token,    31.90 tokens per second)\n",
      "llama_print_timings:       total time =     602.74 ms /   517 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.22 ms /     6 runs   (    0.20 ms per token,  4930.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     174.82 ms /    37 tokens (    4.72 ms per token,   211.64 tokens per second)\n",
      "llama_print_timings:        eval time =     154.99 ms /     5 runs   (   31.00 ms per token,    32.26 tokens per second)\n",
      "llama_print_timings:       total time =     339.52 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_card\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     4 runs   (    0.20 ms per token,  5018.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.87 ms /   292 tokens (    0.99 ms per token,  1007.34 tokens per second)\n",
      "llama_print_timings:        eval time =      92.67 ms /     3 runs   (   30.89 ms per token,    32.37 tokens per second)\n",
      "llama_print_timings:       total time =     388.80 ms /   295 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_card\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /     9 runs   (    0.20 ms per token,  5064.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.85 ms /   121 tokens (    1.64 ms per token,   608.50 tokens per second)\n",
      "llama_print_timings:        eval time =     249.43 ms /     8 runs   (   31.18 ms per token,    32.07 tokens per second)\n",
      "llama_print_timings:       total time =     463.84 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mortgages_and_loans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     5 runs   (    0.19 ms per token,  5399.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     382.10 ms /   422 tokens (    0.91 ms per token,  1104.41 tokens per second)\n",
      "llama_print_timings:        eval time =     126.43 ms /     4 runs   (   31.61 ms per token,    31.64 tokens per second)\n",
      "llama_print_timings:       total time =     516.99 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     4 runs   (    0.19 ms per token,  5141.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     226.26 ms /   184 tokens (    1.23 ms per token,   813.24 tokens per second)\n",
      "llama_print_timings:        eval time =      93.74 ms /     3 runs   (   31.25 ms per token,    32.00 tokens per second)\n",
      "llama_print_timings:       total time =     326.62 ms /   187 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " debt_collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /     5 runs   (    0.20 ms per token,  4921.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     436.92 ms /   512 tokens (    0.85 ms per token,  1171.84 tokens per second)\n",
      "llama_print_timings:        eval time =     159.94 ms /     5 runs   (   31.99 ms per token,    31.26 tokens per second)\n",
      "llama_print_timings:       total time =     606.27 ms /   517 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /     5 runs   (    0.21 ms per token,  4873.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.11 ms /   611 tokens (    1.05 ms per token,   951.55 tokens per second)\n",
      "llama_print_timings:        eval time =     125.66 ms /     4 runs   (   31.42 ms per token,    31.83 tokens per second)\n",
      "llama_print_timings:       total time =     779.09 ms /   615 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " retail_banking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     4 runs   (    0.19 ms per token,  5369.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.75 ms /  1430 tokens (    0.95 ms per token,  1049.35 tokens per second)\n",
      "llama_print_timings:        eval time =      96.72 ms /     3 runs   (   32.24 ms per token,    31.02 tokens per second)\n",
      "llama_print_timings:       total time =    1471.95 ms /  1433 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_card\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.61 ms /     7 runs   (    0.23 ms per token,  4358.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     215.65 ms /   166 tokens (    1.30 ms per token,   769.78 tokens per second)\n",
      "llama_print_timings:        eval time =     185.86 ms /     6 runs   (   30.98 ms per token,    32.28 tokens per second)\n",
      "llama_print_timings:       total time =     413.82 ms /   172 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /     7 runs   (    0.20 ms per token,  5068.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     302.50 ms /   338 tokens (    0.89 ms per token,  1117.34 tokens per second)\n",
      "llama_print_timings:        eval time =     189.23 ms /     6 runs   (   31.54 ms per token,    31.71 tokens per second)\n",
      "llama_print_timings:       total time =     503.14 ms /   344 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    11 runs   (    0.18 ms per token,  5629.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.13 ms /   124 tokens (    1.62 ms per token,   616.52 tokens per second)\n",
      "llama_print_timings:        eval time =     313.00 ms /    10 runs   (   31.30 ms per token,    31.95 tokens per second)\n",
      "llama_print_timings:       total time =     532.32 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mortgages_and_loans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /     7 runs   (    0.20 ms per token,  4929.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     208.49 ms /   134 tokens (    1.56 ms per token,   642.73 tokens per second)\n",
      "llama_print_timings:        eval time =     188.52 ms /     6 runs   (   31.42 ms per token,    31.83 tokens per second)\n",
      "llama_print_timings:       total time =     408.56 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     4 runs   (    0.16 ms per token,  6106.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.35 ms /    89 tokens (    2.16 ms per token,   462.71 tokens per second)\n",
      "llama_print_timings:        eval time =      94.20 ms /     3 runs   (   31.40 ms per token,    31.85 tokens per second)\n",
      "llama_print_timings:       total time =     292.33 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " debt_collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    43 runs   (    0.21 ms per token,  4876.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.81 ms /   124 tokens (    1.61 ms per token,   620.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1299.11 ms /    42 runs   (   30.93 ms per token,    32.33 tokens per second)\n",
      "llama_print_timings:       total time =    1693.05 ms /   166 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mortgages_and_loans or debt_collection (The user's complaint involves a dealer and payments, which could potentially relate to either a mortgage/loan situation or a debt collection issue.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /     5 runs   (    0.20 ms per token,  4906.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     435.21 ms /   507 tokens (    0.86 ms per token,  1164.96 tokens per second)\n",
      "llama_print_timings:        eval time =     128.88 ms /     4 runs   (   32.22 ms per token,    31.04 tokens per second)\n",
      "llama_print_timings:       total time =     572.22 ms /   511 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /     5 runs   (    0.21 ms per token,  4873.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     297.74 ms /   315 tokens (    0.95 ms per token,  1057.96 tokens per second)\n",
      "llama_print_timings:        eval time =     127.03 ms /     4 runs   (   31.76 ms per token,    31.49 tokens per second)\n",
      "llama_print_timings:       total time =     433.97 ms /   319 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_banking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     5 runs   (    0.19 ms per token,  5279.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     430.19 ms /   507 tokens (    0.85 ms per token,  1178.54 tokens per second)\n",
      "llama_print_timings:        eval time =     123.62 ms /     4 runs   (   30.91 ms per token,    32.36 tokens per second)\n",
      "llama_print_timings:       total time =     561.68 ms /   511 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /     7 runs   (    0.20 ms per token,  5083.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.15 ms /   147 tokens (    1.42 ms per token,   702.84 tokens per second)\n",
      "llama_print_timings:        eval time =     183.08 ms /     6 runs   (   30.51 ms per token,    32.77 tokens per second)\n",
      "llama_print_timings:       total time =     403.24 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /     6 runs   (    0.19 ms per token,  5221.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     174.34 ms /    45 tokens (    3.87 ms per token,   258.12 tokens per second)\n",
      "llama_print_timings:        eval time =     154.11 ms /     5 runs   (   30.82 ms per token,    32.45 tokens per second)\n",
      "llama_print_timings:       total time =     337.86 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_card\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     5 runs   (    0.18 ms per token,  5470.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     429.44 ms /   512 tokens (    0.84 ms per token,  1192.26 tokens per second)\n",
      "llama_print_timings:        eval time =     155.22 ms /     5 runs   (   31.04 ms per token,    32.21 tokens per second)\n",
      "llama_print_timings:       total time =     593.96 ms /   517 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /     5 runs   (    0.23 ms per token,  4416.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     380.17 ms /   422 tokens (    0.90 ms per token,  1110.03 tokens per second)\n",
      "llama_print_timings:        eval time =     124.33 ms /     4 runs   (   31.08 ms per token,    32.17 tokens per second)\n",
      "llama_print_timings:       total time =     513.95 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     5 runs   (    0.19 ms per token,  5230.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     434.52 ms /   507 tokens (    0.86 ms per token,  1166.81 tokens per second)\n",
      "llama_print_timings:        eval time =     126.15 ms /     4 runs   (   31.54 ms per token,    31.71 tokens per second)\n",
      "llama_print_timings:       total time =     569.19 ms /   511 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /     7 runs   (    0.18 ms per token,  5409.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.31 ms /   105 tokens (    1.84 ms per token,   543.18 tokens per second)\n",
      "llama_print_timings:        eval time =     184.93 ms /     6 runs   (   30.82 ms per token,    32.44 tokens per second)\n",
      "llama_print_timings:       total time =     389.39 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     5 runs   (    0.18 ms per token,  5458.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     381.57 ms /   423 tokens (    0.90 ms per token,  1108.58 tokens per second)\n",
      "llama_print_timings:        eval time =     127.87 ms /     4 runs   (   31.97 ms per token,    31.28 tokens per second)\n",
      "llama_print_timings:       total time =     518.04 ms /   427 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     5 runs   (    0.19 ms per token,  5336.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     385.56 ms /   434 tokens (    0.89 ms per token,  1125.63 tokens per second)\n",
      "llama_print_timings:        eval time =     124.78 ms /     4 runs   (   31.20 ms per token,    32.06 tokens per second)\n",
      "llama_print_timings:       total time =     518.14 ms /   438 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     5 runs   (    0.18 ms per token,  5668.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     155.88 ms /     5 runs   (   31.18 ms per token,    32.08 tokens per second)\n",
      "llama_print_timings:       total time =     163.75 ms /     6 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n",
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    11 runs   (    0.19 ms per token,  5208.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.86 ms /    99 tokens (    1.95 ms per token,   513.33 tokens per second)\n",
      "llama_print_timings:        eval time =     311.01 ms /    10 runs   (   31.10 ms per token,    32.15 tokens per second)\n",
      "llama_print_timings:       total time =     521.60 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mortgages_and_loans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /     7 runs   (    0.20 ms per token,  5014.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     244.33 ms /   204 tokens (    1.20 ms per token,   834.93 tokens per second)\n",
      "llama_print_timings:        eval time =     185.77 ms /     6 runs   (   30.96 ms per token,    32.30 tokens per second)\n",
      "llama_print_timings:       total time =     441.09 ms /   210 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     5 runs   (    0.17 ms per token,  5813.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     381.23 ms /   422 tokens (    0.90 ms per token,  1106.95 tokens per second)\n",
      "llama_print_timings:        eval time =     124.12 ms /     4 runs   (   31.03 ms per token,    32.23 tokens per second)\n",
      "llama_print_timings:       total time =     512.95 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     5 runs   (    0.19 ms per token,  5257.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     156.98 ms /     5 runs   (   31.40 ms per token,    31.85 tokens per second)\n",
      "llama_print_timings:       total time =     165.71 ms /     6 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n",
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    33 runs   (    0.20 ms per token,  5055.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     177.21 ms /    55 tokens (    3.22 ms per token,   310.36 tokens per second)\n",
      "llama_print_timings:        eval time =     979.35 ms /    32 runs   (   30.60 ms per token,    32.67 tokens per second)\n",
      "llama_print_timings:       total time =    1209.81 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mortgages_and_loans or retail_banking (Depending on the nature of the lease and the company involved, it could be either.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /     7 runs   (    0.20 ms per token,  4961.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     211.66 ms /   151 tokens (    1.40 ms per token,   713.41 tokens per second)\n",
      "llama_print_timings:        eval time =     183.52 ms /     6 runs   (   30.59 ms per token,    32.69 tokens per second)\n",
      "llama_print_timings:       total time =     406.54 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mortgage_and_loans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     5 runs   (    0.18 ms per token,  5643.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     382.15 ms /   422 tokens (    0.91 ms per token,  1104.28 tokens per second)\n",
      "llama_print_timings:        eval time =     123.46 ms /     4 runs   (   30.86 ms per token,    32.40 tokens per second)\n",
      "llama_print_timings:       total time =     513.68 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     5 runs   (    0.18 ms per token,  5405.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     386.11 ms /   434 tokens (    0.89 ms per token,  1124.04 tokens per second)\n",
      "llama_print_timings:        eval time =     125.08 ms /     4 runs   (   31.27 ms per token,    31.98 tokens per second)\n",
      "llama_print_timings:       total time =     519.08 ms /   438 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " credit_reporting\n"
     ]
    }
   ],
   "source": [
    "# example - new_data['mistral_response_cleaned'] = new_data['narrative'].apply(lambda x:______ )\n",
    "#new_data['mistral_response'] = new_data['narrative'].apply(lambda x: \"_____\")\n",
    "new_data['mistral_response'] = new_data['narrative'].apply(lambda x: generate_mistral_response(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "rA9KYTgxDh2F"
   },
   "outputs": [],
   "source": [
    "# example - new_data['mistral_response_cleaned'] = new_data['narrative'].apply(lambda x:______ )\n",
    "#new_data['mistral_response_cleaned'] = new_data['mistral_response'].apply(lambda x: \"_____\")\n",
    "new_data['mistral_response_cleaned'] = new_data['mistral_response'].apply(lambda x: extract_category(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plQNsfl0EDSG",
    "tags": []
   },
   "source": [
    "##### **Q3.2: Calculate the F1 score** **(1 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "7WXEgmPKEIoi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.84\n",
      "F1 Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score for 'product' and 'mistral_response'\n",
    "f1 = f1_score(new_data['product'], new_data['mistral_response_cleaned'], average='micro')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdtvdEnTEZcG",
    "tags": []
   },
   "source": [
    "##### **Q3.3: Share your observations on the few-shot and zero-shot prompt techniques. (1 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2YrUQkaK0uT"
   },
   "source": [
    "############ Few-shot prompting improves accuracy by showing examples, while zero-shot relies only on instructions and is simpler but often less precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vca9B37WGneH",
    "tags": []
   },
   "source": [
    "# **Section 3: Text to Text generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJlqcsdJBVZx",
    "tags": []
   },
   "source": [
    "### **Question 4: Zero-Shot Prompting for Text Summarization (5 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDFS-VMEIEZs",
    "tags": []
   },
   "source": [
    "##### **Q4.1: Define the Prompt Template, System Message, generate prompt and model response** **(3 Marks)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJoScpBlBVZx",
    "tags": []
   },
   "source": [
    "- Define a **system message** as a string and assign it to the variable system_message to generate summary of narrative in data.\n",
    "- Create a **zero shot prompt template** that incorporates the system message and user input.\n",
    "- Define **generate_prompt** function that takes both the system_message and user_input as arguments and formats them into a prompt template\n",
    "\n",
    "\n",
    "Write a Python function called **generate_mistral_response** that takes a single parameter, narrative, which represents the user's complain. Inside the function, you should perform the following tasks:\n",
    "\n",
    "\n",
    "- **Combine the system_message and narrative to create a prompt string using generate_prompt function.**\n",
    "\n",
    "*Generate a response from the Mistral model using the lcpp_llm instance with the following parameters:*\n",
    "\n",
    "- prompt should be the combined prompt string.\n",
    "- max_tokens should be set to 1200.\n",
    "- temperature should be set to 0.\n",
    "- top_p should be set to 0.95.\n",
    "- repeat_penalty should be set to 1.2.\n",
    "- top_k should be set to 50.\n",
    "- stop should be set as a list containing '/s'.\n",
    "- echo should be set to False.\n",
    "Extract and return the response text from the generated response.\n",
    "\n",
    "Don't forget to provide a value for the system_message variable before using it in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7PewmIuBII56"
   },
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant that generates a concise summary of the given complaint narrative.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "czkz3BMpL2ek"
   },
   "outputs": [],
   "source": [
    "zero_shot_prompt_template = \"\"\"[System Message]\n",
    "{system_message}\n",
    "\n",
    "[User Complaint]\n",
    "{user_input}\n",
    "\n",
    "[Summary]\n",
    "\"\"\"\n",
    "def generate_prompt(system_message,user_input):\n",
    "    prompt=zero_shot_prompt_template.format(system_message=system_message,user_input =user_input)\n",
    "    return prompt\n",
    "\n",
    "def generate_mistral_response(input_text):\n",
    "\n",
    "    # Combine user_prompt and system_message to create the prompt\n",
    "    prompt = generate_prompt(system_message,input_text)\n",
    "\n",
    "    # Define the Llama model along with its parameters for generating a response\n",
    "    response = lcpp_llm(\n",
    "        prompt=prompt,\n",
    "        max_tokens=1200,\n",
    "        temperature=0,\n",
    "        top_p=0.95,\n",
    "        repeat_penalty=1.2,\n",
    "        top_k=50,\n",
    "        stop=[\"/s\"],\n",
    "        echo=False\n",
    "    )\n",
    "\n",
    "\n",
    "    # Extract and return the response text\n",
    "    response_text = response[\"choices\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpiIHpThMtW6",
    "tags": []
   },
   "source": [
    "##### **Q4.2: Generate mistral_response column containing LLM generated summaries** **(1 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Fqxl54MMMBTu"
   },
   "outputs": [],
   "source": [
    "# Randomly select 30 rows\n",
    "gold_examples = data.sample(30, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "1kWS3MmUMEgc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      33.14 ms /   163 runs   (    0.20 ms per token,  4918.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     248.31 ms /   247 tokens (    1.01 ms per token,   994.71 tokens per second)\n",
      "llama_print_timings:        eval time =    5066.79 ms /   162 runs   (   31.28 ms per token,    31.97 tokens per second)\n",
      "llama_print_timings:       total time =    5602.62 ms /   409 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is reporting a fraudulent charge on their Capital One checking account, which was immediately canceled. They disputed the charge and were informed that provisional credit would be issued pending determination of the claim. However, they received a form letter denying the claim despite never losing possession of their debit card or authorizing someone else to use it. The user believes their card may have been intercepted and fraudulently activated for unauthorized purchases. They have contacted Capital One multiple times to discuss the original claim and make a determination, but feel that malfeasance is occurring as they were sent a replacement debit card without authorization and had credit purchased on their account without consent. The user has also reported this incident to local police department's financial services division regarding fraudulent activity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      34.99 ms /   169 runs   (    0.21 ms per token,  4830.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     439.50 ms /   506 tokens (    0.87 ms per token,  1151.32 tokens per second)\n",
      "llama_print_timings:        eval time =    5295.43 ms /   168 runs   (   31.52 ms per token,    31.73 tokens per second)\n",
      "llama_print_timings:       total time =    6043.08 ms /   674 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required to block reporting information if a consumer identifies information that resulted from alleged identity theft. The CRA should promptly notify the furnisher of this information and may decline or rescind the block upon reasonable determination, providing evidence whether the consumer was aware of the good service resulting in blocked transactions. Consumers have the right to be notified promptly if their information is reinstated. If a reseller file contains such information, they must provide notice to the consumer. The CRA may apply exceptions for verification companies and check services acting on behalf of consumers. Law enforcement agencies cannot access blocked information without proper authorization or verifiable proof from the original consumer contract. Unverified accounts listed in reports must be removed if the consumer is unable to provide copy verifiable proof.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      34.97 ms /   166 runs   (    0.21 ms per token,  4746.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     224.81 ms /   183 tokens (    1.23 ms per token,   814.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5283.10 ms /   165 runs   (   32.02 ms per token,    31.23 tokens per second)\n",
      "llama_print_timings:       total time =    5814.09 ms /   348 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is disputing USAA for collecting debt on two delinquent accounts that were allegedly opened without their consent. They have provided evidence in the form of mastercard and visa statements, credit card application documents, and a fraud claim. The user claims they did not authorize these accounts and are personally liable for the debts. USAA is accused of creating fraudulent delinquent accounts using private ID data. The user also mentions an unauthorized transaction occurring on one of their existing cards. They have received a response from the Consumer Financial Protection Bureau (CFPB) stating that USAA was found to be liable for the unauthorized transaction. The user is requesting that USAA review and settle the claim, as they believe there are cases of identity theft and criminal activity involved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      35.32 ms /   169 runs   (    0.21 ms per token,  4784.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     448.81 ms /   506 tokens (    0.89 ms per token,  1127.42 tokens per second)\n",
      "llama_print_timings:        eval time =    5377.12 ms /   168 runs   (   32.01 ms per token,    31.24 tokens per second)\n",
      "llama_print_timings:       total time =    6134.79 ms /   674 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required to block reporting information if a consumer identifies information that resulted from alleged identity theft. The CRA should promptly notify the furnisher of this information and may decline or rescind the block upon reasonable determination, providing evidence whether the consumer was aware of the good service resulting in blocked transactions. Consumers have the right to be notified promptly if their information is reinstated. If a reseller file contains such information, they must provide notice to the consumer. The CRA may apply exceptions for verification companies and check services acting on behalf of consumers. Law enforcement agencies cannot access blocked information without proper authorization or verifiable proof from the original consumer contract. Unverified accounts listed in reports must be removed if the consumer is unable to provide copy verifiable proof.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      10.63 ms /    58 runs   (    0.18 ms per token,  5454.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.85 ms /    75 tokens (    2.41 ms per token,   414.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1716.22 ms /    57 runs   (   30.11 ms per token,    33.21 tokens per second)\n",
      "llama_print_timings:       total time =    1991.82 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user has mentioned the opening and closing of multiple balance accounts several times. It appears they are experiencing issues with managing their various accounts, possibly due to confusion or errors in record keeping. They may be requesting assistance in organizing or resolving discrepancies related to these accounts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      33.86 ms /   172 runs   (    0.20 ms per token,  5079.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     372.47 ms /   421 tokens (    0.88 ms per token,  1130.30 tokens per second)\n",
      "llama_print_timings:        eval time =    5306.02 ms /   171 runs   (   31.03 ms per token,    32.23 tokens per second)\n",
      "llama_print_timings:       total time =    5982.80 ms /   592 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required to block certain reporting information in a consumer's file if the consumer identifies information that resulted from alleged identity theft. The CRA must promptly notify any business furnishing information about the consumer of this block, and the furnisher must decline or rescind the report related to the blocked transaction. If the CRA determines that the block was an error, it shall remove the block upon receiving appropriate proof from the consumer. Additionally, if a reseller files a consumer report concerning identified information, they are required to inform the consumer of their decision and provide them with contact details for the CRA. The check service company must also apply certain provisions when processing negotiable instruments or electronic fund transfers related to blocked transactions. Access to blocked information by law enforcement agencies is restricted under specific circumstances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      25.58 ms /   125 runs   (    0.20 ms per token,  4886.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.65 ms /    88 tokens (    2.18 ms per token,   459.16 tokens per second)\n",
      "llama_print_timings:        eval time =    3951.04 ms /   124 runs   (   31.86 ms per token,    31.38 tokens per second)\n",
      "llama_print_timings:       total time =    4371.03 ms /   212 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is having issues with PenFed in regards to closing a loan. They have been asked to provide proof of income, including payment stubs and account statements, as well as tax forms. The user has also formally applied for the loan but PenFed is asking for additional documentation such as deposit statements, checks, and transfer accounts. Additionally, they were requested to provide an invoice related to legal services rendered which they believe violates their privilege. They have provided a copy of the invoice but are concerned that PenFed may be going beyond what's necessary in evaluating their income payment capacity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      34.12 ms /   172 runs   (    0.20 ms per token,  5041.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     387.33 ms /   421 tokens (    0.92 ms per token,  1086.92 tokens per second)\n",
      "llama_print_timings:        eval time =    5431.01 ms /   171 runs   (   31.76 ms per token,    31.49 tokens per second)\n",
      "llama_print_timings:       total time =    6127.21 ms /   592 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required to block certain reporting information in a consumer's file if the consumer identifies information that resulted from alleged identity theft. The CRA must promptly notify any business furnishing information about the consumer of this block, and the furnisher must decline or rescind the report related to the blocked transaction. If the CRA determines that the block was an error, it shall remove the block upon receiving appropriate proof from the consumer. Additionally, if a reseller files a consumer report concerning identified information, they are required to inform the consumer of their decision and provide them with contact details for the CRA. The check service company must also apply certain provisions when processing negotiable instruments or electronic fund transfers related to blocked transactions. Access to blocked information by law enforcement agencies is restricted under specific circumstances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      35.94 ms /   171 runs   (    0.21 ms per token,  4757.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.88 ms /   433 tokens (    0.91 ms per token,  1096.53 tokens per second)\n",
      "llama_print_timings:        eval time =    5492.19 ms /   170 runs   (   32.31 ms per token,    30.95 tokens per second)\n",
      "llama_print_timings:       total time =    6198.79 ms /   603 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required to block reporting of certain consumer information if the consumer identifies it as being a result of alleged identity theft. The CRA must promptly notify any business that has furnished such information and may decline or rescind the blocking request based on specific reasons. If an error occurs, the consumer can request reinstatement of the blocked information. Consumers have the right to be notified in a timely manner if their information is declined or rescinded. The CRA must also block any subsequent use of this information according to the provision. Resellers are obligated to provide notice to consumers when they obtain and resell consumer reports containing blocked information, and check service companies have exceptions for verifying transactions. Law enforcement agencies cannot access blocked information without a specific requirement in law.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      34.87 ms /   172 runs   (    0.20 ms per token,  4933.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     400.66 ms /   421 tokens (    0.95 ms per token,  1050.77 tokens per second)\n",
      "llama_print_timings:        eval time =    5539.68 ms /   171 runs   (   32.40 ms per token,    30.87 tokens per second)\n",
      "llama_print_timings:       total time =    6254.89 ms /   592 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required to block certain reporting information in a consumer's file if the consumer identifies information that resulted from alleged identity theft. The CRA must promptly notify any business furnishing information about the consumer of this block, and the furnisher must decline or rescind the report related to the blocked transaction. If the CRA determines that the block was an error, it shall remove the block upon receiving appropriate proof from the consumer. Additionally, if a reseller files a consumer report concerning identified information, they are required to inform the consumer of their decision and provide them with contact details for the CRA. The check service company must also apply certain provisions when processing negotiable instruments or electronic fund transfers related to blocked transactions. Access to blocked information by law enforcement agencies is restricted under specific circumstances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      31.92 ms /   155 runs   (    0.21 ms per token,  4855.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     212.97 ms /   148 tokens (    1.44 ms per token,   694.93 tokens per second)\n",
      "llama_print_timings:        eval time =    4870.30 ms /   154 runs   (   31.63 ms per token,    31.62 tokens per second)\n",
      "llama_print_timings:       total time =    5373.42 ms /   302 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is a victim of identity theft and has discovered false, fraudulent information on their credit report related to transactions made without their consent. They believe these incidents occurred as a result of the Equifax data breach. The user has contacted Equifax to lock their account and request that the inaccurate information be removed. However, they have had difficulty communicating with the company and validating their identity. Additionally, they have reported the fraudulent activity to local police and the Federal Trade Commission (FTC). They are also experiencing adverse actions due to the incorrect reporting on their credit report, making it difficult for them to find employment. The user is requesting assistance in effectively communicating with Equifax and creditor agencies to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      41.97 ms /   205 runs   (    0.20 ms per token,  4884.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     441.01 ms /   512 tokens (    0.86 ms per token,  1160.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6401.13 ms /   204 runs   (   31.38 ms per token,    31.87 tokens per second)\n",
      "llama_print_timings:       total time =    7217.21 ms /   716 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required by law to block reporting information if a consumer identifies information that resulted from alleged identity theft. The CRA should promptly notify the furnisher of this information and may decline or rescind the block upon reasonable determination, providing evidence whether the consumer was aware of the good service resulting in blocked transactions. Consumers have the right to be notified promptly if their information is reinstated. If a reseller file contains such information, they must apply the same rules as the CRA and inform consumers accordingly. The Check Service Company acting on an authorization purpose should report this information to the National Consumer Reporting Agency but cannot access blocked information without proper verification. Law enforcement agencies also have limited access to these records under specific circumstances. Unverified accounts must be removed from consumer reports if the consumer is unable to provide verifiable proof, and the CRA could face consequences for failing to positively verify an account or listing a fraudulent one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      33.90 ms /   172 runs   (    0.20 ms per token,  5073.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     379.12 ms /   421 tokens (    0.90 ms per token,  1110.45 tokens per second)\n",
      "llama_print_timings:        eval time =    5409.43 ms /   171 runs   (   31.63 ms per token,    31.61 tokens per second)\n",
      "llama_print_timings:       total time =    6094.96 ms /   592 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required to block certain reporting information in a consumer's file if the consumer identifies information that resulted from alleged identity theft. The CRA must promptly notify any business furnishing information about the consumer of this block, and the furnisher must decline or rescind the report related to the blocked transaction. If the CRA determines that the block was an error, it shall remove the block upon receiving appropriate proof from the consumer. Additionally, if a reseller files a consumer report concerning identified information, they are required to inform the consumer of their decision and provide them with contact details for the CRA. The check service company must also apply certain provisions when processing negotiable instruments or electronic fund transfers related to blocked transactions. Access to blocked information by law enforcement agencies is restricted under specific circumstances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      34.63 ms /   167 runs   (    0.21 ms per token,  4822.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.89 ms /   233 tokens (    1.10 ms per token,   907.00 tokens per second)\n",
      "llama_print_timings:        eval time =    5272.13 ms /   166 runs   (   31.76 ms per token,    31.49 tokens per second)\n",
      "llama_print_timings:       total time =    5834.54 ms /   399 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user has been experiencing financial hardships and applied for a mortgage modification. After receiving an initial offer with a discrepancy, the investor agreed to defer principal and extend the loan term to allow for more affordable payments. However, approximately one year later, due to further family losses in income, the user contacted Aurora to request another modification. The process was delayed, and the user expressed concern that the agreement had not been honored as promised. They were told to reapply for the modification, which resulted in a cycle of repeated applications. A housing advocate submitted an escalation request alleging a breach of oral contract and financial loss. Meanwhile, the user received a letter denying their request despite investor agreement. The user fears foreclosure due to their medical condition during the pandemic and urgently needs assistance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      43.94 ms /   205 runs   (    0.21 ms per token,  4665.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     459.87 ms /   512 tokens (    0.90 ms per token,  1113.35 tokens per second)\n",
      "llama_print_timings:        eval time =    6644.92 ms /   204 runs   (   32.57 ms per token,    30.70 tokens per second)\n",
      "llama_print_timings:       total time =    7492.11 ms /   716 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required by law to block reporting information if a consumer identifies information that resulted from alleged identity theft. The CRA should promptly notify the furnisher of this information and may decline or rescind the block upon reasonable determination, providing evidence whether the consumer was aware of the good service resulting in blocked transactions. Consumers have the right to be notified promptly if their information is reinstated. If a reseller file contains such information, they must apply the same rules as the CRA and inform consumers accordingly. The Check Service Company acting on an authorization purpose should report this information to the National Consumer Reporting Agency but cannot access blocked information without proper verification. Law enforcement agencies also have limited access to these records under specific circumstances. Unverified accounts must be removed from consumer reports if the consumer is unable to provide verifiable proof, and the CRA could face consequences for failing to positively verify an account or listing a fraudulent one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      42.85 ms /   215 runs   (    0.20 ms per token,  5017.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.60 ms /   439 tokens (    0.90 ms per token,  1112.52 tokens per second)\n",
      "llama_print_timings:        eval time =    6778.61 ms /   214 runs   (   31.68 ms per token,    31.57 tokens per second)\n",
      "llama_print_timings:       total time =    7568.29 ms /   653 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required to block reporting of certain consumer information if the consumer identifies it as being a result of alleged identity theft. The CRA must promptly block this information from their files on the business day following receipt of appropriate proof from the consumer. However, the CRA may decline or rescind the blocking request based on specific reasons such as material misrepresentation or error. If the block is declined or rescinded, the affected consumer must be notified promptly and in writing. The purpose of this section is to protect consumers from identity theft by preventing the reporting and use of incorrect information. This applies to both the CRA and resellers. Consumers have the right to report identity theft to the bureau and obtain information regarding their case from the reseller. If a check service company issues an authorization for processing a negotiable instrument or electronic fund transfer, they must also report this information to the national consumer reporting agency. Access to blocked information by law enforcement agencies is restricted under certain circumstances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      33.95 ms /   172 runs   (    0.20 ms per token,  5066.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     385.51 ms /   421 tokens (    0.92 ms per token,  1092.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5344.85 ms /   171 runs   (   31.26 ms per token,    31.99 tokens per second)\n",
      "llama_print_timings:       total time =    6036.88 ms /   592 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required to block certain reporting information in a consumer's file if the consumer identifies information that resulted from alleged identity theft. The CRA must promptly notify any business furnishing information about the consumer of this block, and the furnisher must decline or rescind the report related to the blocked transaction. If the CRA determines that the block was an error, it shall remove the block upon receiving appropriate proof from the consumer. Additionally, if a reseller files a consumer report concerning identified information, they are required to inform the consumer of their decision and provide them with contact details for the CRA. The check service company must also apply certain provisions when processing negotiable instruments or electronic fund transfers related to blocked transactions. Access to blocked information by law enforcement agencies is restricted under specific circumstances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      36.42 ms /   178 runs   (    0.20 ms per token,  4887.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     238.51 ms /   194 tokens (    1.23 ms per token,   813.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5646.20 ms /   177 runs   (   31.90 ms per token,    31.35 tokens per second)\n",
      "llama_print_timings:       total time =    6210.05 ms /   371 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user expressed frustration with American Express for reducing their credit limit without prior notice or justification. The representative initially stated the reason was an increase in balance, but later changed their position to say it was due to an increased account balance despite available credit remaining. The user felt taken advantage of as they were paying a significant amount towards their balance and maintaining good standing. They also mentioned that American Express failed to provide a valid reason for the reduction during a time when many people could be experiencing financial hardship, such as illness or workplace closure. The user criticized American Express' business practices and lacked confidence in the representative's handling of the situation. They encouraged American Express to help customers meet their needs during urgent situations and expressed concern that they were creating unnecessary hardships for some members. Additionally, the user felt that the representative lacked proper training and knowledge to handle such situations effectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      24.67 ms /   115 runs   (    0.21 ms per token,  4660.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     211.15 ms /   140 tokens (    1.51 ms per token,   663.03 tokens per second)\n",
      "llama_print_timings:        eval time =    3636.70 ms /   114 runs   (   31.90 ms per token,    31.35 tokens per second)\n",
      "llama_print_timings:       total time =    4058.55 ms /   254 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is a victim of identity theft following the Equifax data breach. They have filed a claim and are trying to clear their credit report, but have encountered issues with fraudulent items. The process has been long and complicated, causing financial and emotional stress. Additionally, they fear that negative information on their report may prevent them from getting a job due to adverse actions based on inaccurate reporting. They are considering hiring an attorney specializing in predatory loans and breach victim compensation to help review their credit file and remove the fraudulent items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      47.39 ms /   224 runs   (    0.21 ms per token,  4726.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     327.38 ms /   359 tokens (    0.91 ms per token,  1096.58 tokens per second)\n",
      "llama_print_timings:        eval time =    7339.59 ms /   223 runs   (   32.91 ms per token,    30.38 tokens per second)\n",
      "llama_print_timings:       total time =    8095.87 ms /   582 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A divorced service member, who is a single mother and fell behind on mortgage payments after receiving a sudden loss of child support, struggled to modify the loan with her servicing company. She was unable to afford essential repairs and considered filing for deed in lieu of foreclosure due to emotional, physical, and financial strain. However, she wanted to avoid this outcome and tried negotiating a short sale with a broker. The process became complicated when another interested party emerged, and the loan servicing company continued to report late payments, damaging her credit score. Despite these challenges, she managed to make a full payment and contacted the VA to clarify the status of the deed transfer. However, the loan servicer still reported late payments, causing further financial hardship. She was unable to find an attorney willing to represent her case due to her damaged credit score. The situation worsened over several years as she continued to contact the loan servicing company and face late fees and interest accrual. Eventually, she was forced to allow the home to go into foreclosure despite her desire to keep it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      12.89 ms /    68 runs   (    0.19 ms per token,  5273.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.67 ms /    73 tokens (    2.56 ms per token,   391.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2104.25 ms /    67 runs   (   31.41 ms per token,    31.84 tokens per second)\n",
      "llama_print_timings:       total time =    2406.97 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is experiencing identity theft with multiple accounts reported on their TransUnion credit file. They have identified several affected accounts, including those with the account names \"u dept ed,\" \"dpt edxxxx,\" and \"original creditor.\" The user has attempted to contact TransUnion for assistance but has not yet received a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      26.81 ms /   132 runs   (    0.20 ms per token,  4923.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     309.74 ms /   337 tokens (    0.92 ms per token,  1088.00 tokens per second)\n",
      "llama_print_timings:        eval time =    4127.94 ms /   131 runs   (   31.51 ms per token,    31.73 tokens per second)\n",
      "llama_print_timings:       total time =    4673.77 ms /   468 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is experiencing inconsistencies and inaccuracies in their credit report from Equifax. The reported name, last payment date, account status, and credit limit do not match the user's records or reality. They have disputed these issues multiple times but the account remains unchanged. Additionally, an invalid account number was listed as authorized on another reporting account. Despite providing evidence to support their claims, Equifax has refused to make corrections, which is negatively impacting the user's credit score. The user feels obligated by law to request a proper investigation into these errors but has not received satisfactory results from the company.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      23.67 ms /   116 runs   (    0.20 ms per token,  4899.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.43 ms /   112 tokens (    1.76 ms per token,   567.28 tokens per second)\n",
      "llama_print_timings:        eval time =    3647.55 ms /   115 runs   (   31.72 ms per token,    31.53 tokens per second)\n",
      "llama_print_timings:       total time =    4051.49 ms /   227 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is experiencing identity theft and has discovered several fraudulent applications and accounts opened in their name with Equifax. They have disputed the information multiple times, but were told they would receive a response via certified mail. The user is now requesting to initiate a formal complaint due to Equifax's failure to conduct an adequate investigation or block usage of the fraudulent account. They believe this may be a violation of both the Fair Credit Reporting Act and Fair Debt Collection Practices Act, and have also contacted their state attorney general for further assistance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      22.24 ms /   108 runs   (    0.21 ms per token,  4855.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     210.95 ms /   134 tokens (    1.57 ms per token,   635.21 tokens per second)\n",
      "llama_print_timings:        eval time =    3419.78 ms /   107 runs   (   31.96 ms per token,    31.29 tokens per second)\n",
      "llama_print_timings:       total time =    3822.37 ms /   241 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user has filed a complaint about an investigation process regarding a transaction dispute. They claim that the investigator was unable to confirm card possession and gave vague answers, despite providing supporting documentation. The user also mentions being disrespected when requesting a copy of a document proving a debt owed by the cardholder. Additionally, they state that their account has been reported as delinquent to credit reporting companies without resolution or notification. The user is frustrated and wants the situation resolved promptly and requests to close their account.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      28.94 ms /   145 runs   (    0.20 ms per token,  5011.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.11 ms /   291 tokens (    1.02 ms per token,   976.16 tokens per second)\n",
      "llama_print_timings:        eval time =    4577.24 ms /   144 runs   (   31.79 ms per token,    31.46 tokens per second)\n",
      "llama_print_timings:       total time =    5135.50 ms /   435 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user placed multiple orders for products with guaranteed day shipping but received them several weeks later due to high order volume and demand. They followed up via email, were informed of the delay, and paid for two-day shipping. The company apologized and assured they would ship soon, but only small shipments were sent on a first come, first served basis. The user expressed their preference to cancel orders and receive refunds if possible, as they had received some items already. They provided documentation showing the cancellation of one order and the issuance of a refund. However, there seemed to be an issue with another transaction that was disputed, but no resolution or communication regarding this matter was mentioned in the complaint narrative.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      35.13 ms /   172 runs   (    0.20 ms per token,  4895.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     393.16 ms /   421 tokens (    0.93 ms per token,  1070.82 tokens per second)\n",
      "llama_print_timings:        eval time =    5541.40 ms /   171 runs   (   32.41 ms per token,    30.86 tokens per second)\n",
      "llama_print_timings:       total time =    6250.25 ms /   592 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required to block certain reporting information in a consumer's file if the consumer identifies information that resulted from alleged identity theft. The CRA must promptly notify any business furnishing information about the consumer of this block, and the furnisher must decline or rescind the report related to the blocked transaction. If the CRA determines that the block was an error, it shall remove the block upon receiving appropriate proof from the consumer. Additionally, if a reseller files a consumer report concerning identified information, they are required to inform the consumer of their decision and provide them with contact details for the CRA. The check service company must also apply certain provisions when processing negotiable instruments or electronic fund transfers related to blocked transactions. Access to blocked information by law enforcement agencies is restricted under specific circumstances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      27.44 ms /   133 runs   (    0.21 ms per token,  4847.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     202.25 ms /   104 tokens (    1.94 ms per token,   514.22 tokens per second)\n",
      "llama_print_timings:        eval time =    4313.55 ms /   132 runs   (   32.68 ms per token,    30.60 tokens per second)\n",
      "llama_print_timings:       total time =    4766.91 ms /   236 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is a victim of identity theft and has discovered unauthorized transactions on their credit report. They mention that there have been several accounts opened in their name, some with the following account numbers: hlthfrxxxxxxxxxxx, xxxxxxxx, and xxxxxxxx. The dates these accounts were opened are also provided. The user requests that this information be removed from their TransUnion credit report pursuant to the Fair Credit Reporting Act (FCRA). They ask for the necessary steps to be taken by the furnishers of this information and express gratitude while reminding others to wear masks and stay home during these times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      37.59 ms /   183 runs   (    0.21 ms per token,  4867.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.62 ms /   153 tokens (    1.40 ms per token,   712.88 tokens per second)\n",
      "llama_print_timings:        eval time =    5689.58 ms /   182 runs   (   31.26 ms per token,    31.99 tokens per second)\n",
      "llama_print_timings:       total time =    6231.94 ms /   335 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is a victim of identity theft and has discovered unauthorized transactions listed on their Equifax credit report. They have been trying to resolve the issue for an extended period, but it has proven to be complicated and time-consuming. The user fears that they may have been involved in the Equifax data breach and is concerned about potential fraudulent debts hindering their ability to apply for credit or even get a first-time credit card. They are currently reviewing their credit file carefully, considering seeking legal advice from an attorney specializing in identity theft cases, and are eligible for victim compensation. The user has noticed a disputed account on their Equifax report that they have not been able to resolve, causing financial and emotional stress. Additionally, the negative information reported may be hindering their ability to get a job due to adverse actions based on inaccurate credit reporting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      33.90 ms /   169 runs   (    0.20 ms per token,  4985.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     438.92 ms /   506 tokens (    0.87 ms per token,  1152.84 tokens per second)\n",
      "llama_print_timings:        eval time =    5243.94 ms /   168 runs   (   31.21 ms per token,    32.04 tokens per second)\n",
      "llama_print_timings:       total time =    5982.23 ms /   674 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Consumer Reporting Agency (CRA) is required to block reporting information if a consumer identifies information that resulted from alleged identity theft. The CRA should promptly notify the furnisher of this information and may decline or rescind the block upon reasonable determination, providing evidence whether the consumer was aware of the good service resulting in blocked transactions. Consumers have the right to be notified promptly if their information is reinstated. If a reseller file contains such information, they must provide notice to the consumer. The CRA may apply exceptions for verification companies and check services acting on behalf of consumers. Law enforcement agencies cannot access blocked information without proper authorization or verifiable proof from the original consumer contract. Unverified accounts listed in reports must be removed if the consumer is unable to provide copy verifiable proof.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     409.10 ms\n",
      "llama_print_timings:      sample time =      23.75 ms /   121 runs   (    0.20 ms per token,  5094.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.77 ms /    96 tokens (    1.98 ms per token,   505.89 tokens per second)\n",
      "llama_print_timings:        eval time =    3660.47 ms /   120 runs   (   30.50 ms per token,    32.78 tokens per second)\n",
      "llama_print_timings:       total time =    4060.06 ms /   216 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user's mother called to remove an authorized user from her credit card who had never used the line. However, this action negatively affected the user's credit score. The user was able to contact Experian and dispute the change but is eagerly waiting for the reflection of the correction in their score. They need a good credit score to refinance their home as their husband has lost his job and they are barely making ends meet with a nurse's salary. Despite trying to dispute online, the user was unable to get through to Experian by phone to further discuss the issue.\n"
     ]
    }
   ],
   "source": [
    "# example - new_data['mistral_response_cleaned'] = new_data['narrative'].apply(lambda x:______ )\n",
    "gold_examples['mistral_response'] = gold_examples['narrative'].apply(lambda x: generate_mistral_response(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dl-5fRKbND2n",
    "tags": []
   },
   "source": [
    "##### **Q4.3: Evaluate bert score** **(1 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "H6SqvLIeMVN-"
   },
   "outputs": [],
   "source": [
    "def evaluate_score(test_data, scorer, bert_score=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Return the ROUGE score or BERTScore for predictions on gold examples\n",
    "    For each example we make a prediction using the prompt.\n",
    "    Gold summaries and the AI generated summaries are aggregated into lists.\n",
    "    These lists are used by the corresponding scorers to compute metrics.\n",
    "    Since BERTScore is computed for each candidate-reference pair, we take the\n",
    "    average F1 score across the gold examples.\n",
    "\n",
    "    Args:\n",
    "        prompt (List): list of messages in the Open AI prompt format\n",
    "        gold_examples (str): JSON string with list of gold examples\n",
    "        scorer (function): Scorer function used to compute the ROUGE score or the\n",
    "                           BERTScore\n",
    "        bert_score (boolean): A flag variable that indicates if BERTScore should\n",
    "                              be used as the metric.\n",
    "\n",
    "    Output:\n",
    "        score (float): BERTScore or ROUGE score computed by comparing model predictions\n",
    "                       with ground truth\n",
    "    \"\"\"\n",
    "\n",
    "    model_predictions = test_data['mistral_response'].tolist()\n",
    "    ground_truths = test_data['summary'].tolist()\n",
    "    if bert_score:\n",
    "        score = scorer.compute(\n",
    "            predictions=model_predictions,\n",
    "            references=ground_truths,\n",
    "            lang=\"en\",\n",
    "            rescale_with_baseline=True\n",
    "        )\n",
    "\n",
    "        return sum(score['f1'])/len(score['f1'])\n",
    "    else:\n",
    "        return scorer.compute(\n",
    "            predictions=model_predictions,\n",
    "            references=ground_truths\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "4T4k6rA_MlS-"
   },
   "outputs": [],
   "source": [
    "bert_scorer = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ikncTGPBNPRb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore: 0.3519383544723193\n"
     ]
    }
   ],
   "source": [
    "score = evaluate_score(\n",
    "    gold_examples,   \n",
    "    bert_scorer,\n",
    "    bert_score=True\n",
    ")\n",
    "\n",
    "\n",
    "print(f'BERTScore: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "XcGMygn3_Mq9",
    "GdQdNav7AOtV",
    "T9t6gsZVsL2b",
    "803ZuG7OtSSj",
    "plQNsfl0EDSG",
    "IdtvdEnTEZcG",
    "dl-5fRKbND2n",
    "-p6_jPcVNWz7"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
